{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Nygdl2G9Nieo"
   },
   "outputs": [],
   "source": [
    "# load the 2 npy files created by the process_yale_images.ipynb \n",
    "from numpy import load\n",
    "import numpy as np\n",
    "\n",
    "# load array\n",
    "y = load('./yaleExtB_target.npy')\n",
    "X = load('./yaleExtB_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Th62dSshOXqa"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # loads functions from the ML library sklearn \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uz5JnDUOOgEw"
   },
   "outputs": [],
   "source": [
    "# split into a training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "I3HtYdw6Oj6J"
   },
   "outputs": [],
   "source": [
    "# PCA \n",
    "nof_prin_components = 200  # PARAMETER for optimisation in expereiments\n",
    "pca = PCA(n_components=nof_prin_components, whiten=True).fit(X_train)\n",
    "\n",
    "# applies PCA to the train and test images to calculate the principal components\n",
    "X_train_pca = pca.transform(X_train) \n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 36.,  42.,  52., ..., 128., 117., 115.],\n",
       "       [ 26.,  28.,  26., ...,   1.,   1.,   1.],\n",
       "       [162., 171., 175., ...,   8.,  11.,  13.],\n",
       "       ...,\n",
       "       [158., 160., 128., ...,   7.,   7.,   7.],\n",
       "       [ 42.,  44.,  32., ...,  18.,  20.,  20.],\n",
       "       [103., 103., 105., ...,  32.,  20.,  19.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.38201553,  0.52723044, -0.4183909 ,  0.27821595, -1.49481838,\n",
       "       -0.2725399 , -0.09086642,  0.54044361, -0.40700769,  0.87881918,\n",
       "       -0.08399127,  1.94185768,  0.84273627, -1.56530585, -1.48482597,\n",
       "        0.60966217, -0.88148971,  0.99381291,  0.19866044, -0.97484169,\n",
       "       -0.72403833,  0.08146954, -1.01229255, -0.34948632,  1.05558962,\n",
       "       -0.86539703,  1.66766705,  1.86029561,  0.02198214,  0.15722326,\n",
       "        0.13829593,  0.34539639, -0.0105105 , -0.91877239,  0.54167804,\n",
       "        1.01101864, -0.22923436,  0.15145705, -0.08945736, -0.09765085,\n",
       "        1.05682228,  0.9339385 , -0.51700293,  0.68179283, -0.31757761,\n",
       "        1.28712294, -0.46977323, -0.95797275,  0.39567176, -0.56380596,\n",
       "       -1.3390784 , -0.76515164,  0.4063293 , -0.2414999 , -0.22349709,\n",
       "        0.32013716, -0.30503687, -0.14282279, -1.02280546, -0.21727412,\n",
       "       -0.62197681, -1.00132388,  0.75041771, -1.72639612, -1.24418955,\n",
       "       -1.27235687, -0.62112123,  1.73093036,  0.22052455,  0.94826444,\n",
       "        1.41551186, -0.19417069,  0.66767025,  0.83741361, -0.76689699,\n",
       "        0.5901485 ,  0.14541126,  0.25575694,  0.15709313, -0.84285951,\n",
       "       -0.40275675, -0.72631871,  0.52308065, -0.76281774, -0.11909763,\n",
       "       -0.34118424, -0.10608686,  0.84693577,  0.04276743, -0.66817359,\n",
       "       -0.31742678, -0.0878467 , -0.1800946 , -2.24579031,  0.2751255 ,\n",
       "       -0.44996365, -0.40049286, -1.39030011, -2.47260053,  0.39915332,\n",
       "       -0.56825155,  0.50832661, -0.52681245, -0.1929609 ,  1.1550354 ,\n",
       "       -0.6965584 ,  1.44868454,  0.97856096,  0.1778122 , -1.79108908,\n",
       "       -0.95877139,  0.10421239,  0.06741917, -0.89773895,  0.52032967,\n",
       "       -0.96667235,  0.48518905, -0.61121791,  2.32525089, -2.04006443,\n",
       "       -2.10036776,  0.27887956,  0.49801744,  0.61864919,  1.48035262,\n",
       "        0.80291081, -0.30659669,  0.74398055,  0.88305512,  0.63861222,\n",
       "        1.0630739 ,  0.20183075,  0.54240834,  0.05300305,  0.44240729,\n",
       "       -0.85546437,  0.71466839, -0.19111358, -0.68463988,  0.66108327,\n",
       "        0.56459273, -0.67591022,  0.38279234, -0.99111478,  0.4954584 ,\n",
       "       -0.20787386, -0.23353864,  0.07692469,  1.17969116,  0.30311883,\n",
       "        0.72111703,  0.35888149,  0.86982019,  0.53553146, -1.56735172,\n",
       "       -1.11431273,  0.35942672, -0.79086495, -0.65681347,  0.52844172,\n",
       "       -0.34061738, -0.7106911 ,  0.89142766,  1.05039677,  0.64596065,\n",
       "        0.01442494, -0.0314051 ,  0.4396205 , -0.46500039,  1.19441686,\n",
       "       -0.44470069,  0.15783087, -1.57135933, -0.13442428,  0.98078864,\n",
       "       -0.03770943, -0.43676908, -0.37059075, -0.03900054, -0.07640085,\n",
       "        0.87346511, -0.4345219 , -0.17678985, -0.4684936 , -0.50403733,\n",
       "       -1.24945764, -0.02165437,  0.10616399, -0.31791058, -0.54100247,\n",
       "        1.02107523,  1.21725999, -1.05986225, -0.21618008,  0.54578754,\n",
       "       -0.62779007,  0.35226222,  0.5015969 ,  0.28725284,  0.3765152 ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca[:5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1005, 200)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4PyCqp6PwDl"
   },
   "source": [
    "[Documentation of ML sklearn library](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xZ3tZ3u9On_z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n",
      "Iteration 1, loss = 3.72780358\n",
      "Validation score: 0.029703\n",
      "Iteration 2, loss = 3.71117326\n",
      "Validation score: 0.029703\n",
      "Iteration 3, loss = 3.68579462\n",
      "Validation score: 0.029703\n",
      "Iteration 4, loss = 3.65456628\n",
      "Validation score: 0.039604\n",
      "Iteration 5, loss = 3.61960865\n",
      "Validation score: 0.039604\n",
      "Iteration 6, loss = 3.58257648\n",
      "Validation score: 0.049505\n",
      "Iteration 7, loss = 3.54396312\n",
      "Validation score: 0.049505\n",
      "Iteration 8, loss = 3.50426658\n",
      "Validation score: 0.049505\n",
      "Iteration 9, loss = 3.46415369\n",
      "Validation score: 0.059406\n",
      "Iteration 10, loss = 3.42387452\n",
      "Validation score: 0.059406\n",
      "Iteration 11, loss = 3.38348752\n",
      "Validation score: 0.069307\n",
      "Iteration 12, loss = 3.34307174\n",
      "Validation score: 0.069307\n",
      "Iteration 13, loss = 3.30272193\n",
      "Validation score: 0.079208\n",
      "Iteration 14, loss = 3.26247601\n",
      "Validation score: 0.079208\n",
      "Iteration 15, loss = 3.22261619\n",
      "Validation score: 0.079208\n",
      "Iteration 16, loss = 3.18264275\n",
      "Validation score: 0.079208\n",
      "Iteration 17, loss = 3.14309602\n",
      "Validation score: 0.089109\n",
      "Iteration 18, loss = 3.10397098\n",
      "Validation score: 0.089109\n",
      "Iteration 19, loss = 3.06464896\n",
      "Validation score: 0.089109\n",
      "Iteration 20, loss = 3.02599226\n",
      "Validation score: 0.089109\n",
      "Iteration 21, loss = 2.98723139\n",
      "Validation score: 0.089109\n",
      "Iteration 22, loss = 2.94893569\n",
      "Validation score: 0.099010\n",
      "Iteration 23, loss = 2.91104828\n",
      "Validation score: 0.118812\n",
      "Iteration 24, loss = 2.87323226\n",
      "Validation score: 0.128713\n",
      "Iteration 25, loss = 2.83548723\n",
      "Validation score: 0.138614\n",
      "Iteration 26, loss = 2.79832340\n",
      "Validation score: 0.148515\n",
      "Iteration 27, loss = 2.76154811\n",
      "Validation score: 0.158416\n",
      "Iteration 28, loss = 2.72484394\n",
      "Validation score: 0.158416\n",
      "Iteration 29, loss = 2.68850056\n",
      "Validation score: 0.178218\n",
      "Iteration 30, loss = 2.65230290\n",
      "Validation score: 0.188119\n",
      "Iteration 31, loss = 2.61673135\n",
      "Validation score: 0.198020\n",
      "Iteration 32, loss = 2.58145141\n",
      "Validation score: 0.217822\n",
      "Iteration 33, loss = 2.54638110\n",
      "Validation score: 0.227723\n",
      "Iteration 34, loss = 2.51161950\n",
      "Validation score: 0.237624\n",
      "Iteration 35, loss = 2.47708975\n",
      "Validation score: 0.257426\n",
      "Iteration 36, loss = 2.44323658\n",
      "Validation score: 0.257426\n",
      "Iteration 37, loss = 2.40930695\n",
      "Validation score: 0.277228\n",
      "Iteration 38, loss = 2.37590424\n",
      "Validation score: 0.287129\n",
      "Iteration 39, loss = 2.34281749\n",
      "Validation score: 0.287129\n",
      "Iteration 40, loss = 2.31002360\n",
      "Validation score: 0.306931\n",
      "Iteration 41, loss = 2.27758444\n",
      "Validation score: 0.316832\n",
      "Iteration 42, loss = 2.24562624\n",
      "Validation score: 0.356436\n",
      "Iteration 43, loss = 2.21386447\n",
      "Validation score: 0.376238\n",
      "Iteration 44, loss = 2.18254627\n",
      "Validation score: 0.405941\n",
      "Iteration 45, loss = 2.15153304\n",
      "Validation score: 0.425743\n",
      "Iteration 46, loss = 2.12106952\n",
      "Validation score: 0.435644\n",
      "Iteration 47, loss = 2.09078375\n",
      "Validation score: 0.435644\n",
      "Iteration 48, loss = 2.06077229\n",
      "Validation score: 0.435644\n",
      "Iteration 49, loss = 2.03143497\n",
      "Validation score: 0.445545\n",
      "Iteration 50, loss = 2.00215791\n",
      "Validation score: 0.465347\n",
      "Iteration 51, loss = 1.97341741\n",
      "Validation score: 0.465347\n",
      "Iteration 52, loss = 1.94498046\n",
      "Validation score: 0.465347\n",
      "Iteration 53, loss = 1.91705769\n",
      "Validation score: 0.465347\n",
      "Iteration 54, loss = 1.88928853\n",
      "Validation score: 0.465347\n",
      "Iteration 55, loss = 1.86211387\n",
      "Validation score: 0.475248\n",
      "Iteration 56, loss = 1.83522398\n",
      "Validation score: 0.475248\n",
      "Iteration 57, loss = 1.80876188\n",
      "Validation score: 0.485149\n",
      "Iteration 58, loss = 1.78258193\n",
      "Validation score: 0.485149\n",
      "Iteration 59, loss = 1.75689672\n",
      "Validation score: 0.504950\n",
      "Iteration 60, loss = 1.73137703\n",
      "Validation score: 0.514851\n",
      "Iteration 61, loss = 1.70646651\n",
      "Validation score: 0.514851\n",
      "Iteration 62, loss = 1.68176815\n",
      "Validation score: 0.514851\n",
      "Iteration 63, loss = 1.65751829\n",
      "Validation score: 0.524752\n",
      "Iteration 64, loss = 1.63364076\n",
      "Validation score: 0.524752\n",
      "Iteration 65, loss = 1.61011624\n",
      "Validation score: 0.544554\n",
      "Iteration 66, loss = 1.58684324\n",
      "Validation score: 0.544554\n",
      "Iteration 67, loss = 1.56394759\n",
      "Validation score: 0.544554\n",
      "Iteration 68, loss = 1.54151685\n",
      "Validation score: 0.554455\n",
      "Iteration 69, loss = 1.51942219\n",
      "Validation score: 0.554455\n",
      "Iteration 70, loss = 1.49772606\n",
      "Validation score: 0.554455\n",
      "Iteration 71, loss = 1.47611928\n",
      "Validation score: 0.564356\n",
      "Iteration 72, loss = 1.45504991\n",
      "Validation score: 0.564356\n",
      "Iteration 73, loss = 1.43438519\n",
      "Validation score: 0.564356\n",
      "Iteration 74, loss = 1.41378439\n",
      "Validation score: 0.564356\n",
      "Iteration 75, loss = 1.39382540\n",
      "Validation score: 0.564356\n",
      "Iteration 76, loss = 1.37406540\n",
      "Validation score: 0.564356\n",
      "Iteration 77, loss = 1.35454844\n",
      "Validation score: 0.574257\n",
      "Iteration 78, loss = 1.33547953\n",
      "Validation score: 0.574257\n",
      "Iteration 79, loss = 1.31656866\n",
      "Validation score: 0.574257\n",
      "Iteration 80, loss = 1.29811091\n",
      "Validation score: 0.574257\n",
      "Iteration 81, loss = 1.27989034\n",
      "Validation score: 0.584158\n",
      "Iteration 82, loss = 1.26207432\n",
      "Validation score: 0.594059\n",
      "Iteration 83, loss = 1.24441552\n",
      "Validation score: 0.594059\n",
      "Iteration 84, loss = 1.22706209\n",
      "Validation score: 0.594059\n",
      "Iteration 85, loss = 1.21009635\n",
      "Validation score: 0.603960\n",
      "Iteration 86, loss = 1.19328954\n",
      "Validation score: 0.603960\n",
      "Iteration 87, loss = 1.17687716\n",
      "Validation score: 0.623762\n",
      "Iteration 88, loss = 1.16069285\n",
      "Validation score: 0.633663\n",
      "Iteration 89, loss = 1.14478061\n",
      "Validation score: 0.633663\n",
      "Iteration 90, loss = 1.12926278\n",
      "Validation score: 0.633663\n",
      "Iteration 91, loss = 1.11387063\n",
      "Validation score: 0.633663\n",
      "Iteration 92, loss = 1.09876030\n",
      "Validation score: 0.633663\n",
      "Iteration 93, loss = 1.08386053\n",
      "Validation score: 0.643564\n",
      "Iteration 94, loss = 1.06925949\n",
      "Validation score: 0.663366\n",
      "Iteration 95, loss = 1.05496240\n",
      "Validation score: 0.663366\n",
      "Iteration 96, loss = 1.04089066\n",
      "Validation score: 0.663366\n",
      "Iteration 97, loss = 1.02706882\n",
      "Validation score: 0.663366\n",
      "Iteration 98, loss = 1.01332680\n",
      "Validation score: 0.663366\n",
      "Iteration 99, loss = 1.00004442\n",
      "Validation score: 0.673267\n",
      "Iteration 100, loss = 0.98684216\n",
      "Validation score: 0.673267\n",
      "Iteration 101, loss = 0.97389840\n",
      "Validation score: 0.673267\n",
      "Iteration 102, loss = 0.96127392\n",
      "Validation score: 0.683168\n",
      "Iteration 103, loss = 0.94866562\n",
      "Validation score: 0.693069\n",
      "Iteration 104, loss = 0.93646606\n",
      "Validation score: 0.693069\n",
      "Iteration 105, loss = 0.92439168\n",
      "Validation score: 0.693069\n",
      "Iteration 106, loss = 0.91250940\n",
      "Validation score: 0.693069\n",
      "Iteration 107, loss = 0.90074610\n",
      "Validation score: 0.702970\n",
      "Iteration 108, loss = 0.88934741\n",
      "Validation score: 0.702970\n",
      "Iteration 109, loss = 0.87796028\n",
      "Validation score: 0.702970\n",
      "Iteration 110, loss = 0.86693594\n",
      "Validation score: 0.702970\n",
      "Iteration 111, loss = 0.85604154\n",
      "Validation score: 0.712871\n",
      "Iteration 112, loss = 0.84530940\n",
      "Validation score: 0.712871\n",
      "Iteration 113, loss = 0.83473685\n",
      "Validation score: 0.712871\n",
      "Iteration 114, loss = 0.82440679\n",
      "Validation score: 0.722772\n",
      "Iteration 115, loss = 0.81426527\n",
      "Validation score: 0.722772\n",
      "Iteration 116, loss = 0.80413073\n",
      "Validation score: 0.722772\n",
      "Iteration 117, loss = 0.79440904\n",
      "Validation score: 0.732673\n",
      "Iteration 118, loss = 0.78463938\n",
      "Validation score: 0.732673\n",
      "Iteration 119, loss = 0.77513327\n",
      "Validation score: 0.732673\n",
      "Iteration 120, loss = 0.76580267\n",
      "Validation score: 0.732673\n",
      "Iteration 121, loss = 0.75642067\n",
      "Validation score: 0.752475\n",
      "Iteration 122, loss = 0.74741121\n",
      "Validation score: 0.762376\n",
      "Iteration 123, loss = 0.73851119\n",
      "Validation score: 0.762376\n",
      "Iteration 124, loss = 0.72979465\n",
      "Validation score: 0.762376\n",
      "Iteration 125, loss = 0.72112636\n",
      "Validation score: 0.762376\n",
      "Iteration 126, loss = 0.71262795\n",
      "Validation score: 0.772277\n",
      "Iteration 127, loss = 0.70424054\n",
      "Validation score: 0.772277\n",
      "Iteration 128, loss = 0.69612893\n",
      "Validation score: 0.772277\n",
      "Iteration 129, loss = 0.68795412\n",
      "Validation score: 0.772277\n",
      "Iteration 130, loss = 0.68000757\n",
      "Validation score: 0.782178\n",
      "Iteration 131, loss = 0.67222163\n",
      "Validation score: 0.782178\n",
      "Iteration 132, loss = 0.66453680\n",
      "Validation score: 0.782178\n",
      "Iteration 133, loss = 0.65694598\n",
      "Validation score: 0.782178\n",
      "Iteration 134, loss = 0.64950377\n",
      "Validation score: 0.792079\n",
      "Iteration 135, loss = 0.64214982\n",
      "Validation score: 0.792079\n",
      "Iteration 136, loss = 0.63495575\n",
      "Validation score: 0.792079\n",
      "Iteration 137, loss = 0.62784442\n",
      "Validation score: 0.801980\n",
      "Iteration 138, loss = 0.62092253\n",
      "Validation score: 0.801980\n",
      "Iteration 139, loss = 0.61401792\n",
      "Validation score: 0.811881\n",
      "Iteration 140, loss = 0.60734562\n",
      "Validation score: 0.821782\n",
      "Iteration 141, loss = 0.60069862\n",
      "Validation score: 0.821782\n",
      "Iteration 142, loss = 0.59407164\n",
      "Validation score: 0.821782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 143, loss = 0.58767578\n",
      "Validation score: 0.821782\n",
      "Iteration 144, loss = 0.58135688\n",
      "Validation score: 0.831683\n",
      "Iteration 145, loss = 0.57504215\n",
      "Validation score: 0.831683\n",
      "Iteration 146, loss = 0.56894428\n",
      "Validation score: 0.831683\n",
      "Iteration 147, loss = 0.56293701\n",
      "Validation score: 0.831683\n",
      "Iteration 148, loss = 0.55693203\n",
      "Validation score: 0.831683\n",
      "Iteration 149, loss = 0.55109497\n",
      "Validation score: 0.831683\n",
      "Iteration 150, loss = 0.54526835\n",
      "Validation score: 0.831683\n",
      "Iteration 151, loss = 0.53969092\n",
      "Validation score: 0.831683\n",
      "Iteration 152, loss = 0.53399966\n",
      "Validation score: 0.831683\n",
      "Iteration 153, loss = 0.52854160\n",
      "Validation score: 0.841584\n",
      "Iteration 154, loss = 0.52311216\n",
      "Validation score: 0.841584\n",
      "Iteration 155, loss = 0.51775635\n",
      "Validation score: 0.841584\n",
      "Iteration 156, loss = 0.51250442\n",
      "Validation score: 0.841584\n",
      "Iteration 157, loss = 0.50735863\n",
      "Validation score: 0.851485\n",
      "Iteration 158, loss = 0.50223050\n",
      "Validation score: 0.851485\n",
      "Iteration 159, loss = 0.49719768\n",
      "Validation score: 0.851485\n",
      "Iteration 160, loss = 0.49225789\n",
      "Validation score: 0.851485\n",
      "Iteration 161, loss = 0.48731571\n",
      "Validation score: 0.851485\n",
      "Iteration 162, loss = 0.48254058\n",
      "Validation score: 0.851485\n",
      "Iteration 163, loss = 0.47778505\n",
      "Validation score: 0.851485\n",
      "Iteration 164, loss = 0.47311771\n",
      "Validation score: 0.851485\n",
      "Iteration 165, loss = 0.46853161\n",
      "Validation score: 0.851485\n",
      "Iteration 166, loss = 0.46398683\n",
      "Validation score: 0.851485\n",
      "Iteration 167, loss = 0.45947275\n",
      "Validation score: 0.851485\n",
      "Iteration 168, loss = 0.45512177\n",
      "Validation score: 0.851485\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, batch_size=250, early_stopping=True,\n",
       "              hidden_layer_sizes=(200,), solver=&#x27;sgd&#x27;, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, batch_size=250, early_stopping=True,\n",
       "              hidden_layer_sizes=(200,), solver=&#x27;sgd&#x27;, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='tanh', batch_size=250, early_stopping=True,\n",
       "              hidden_layer_sizes=(200,), solver='sgd', verbose=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a neural network using MLP\n",
    "nohn = 200 #nof hidden neurons\n",
    "print(\"Fitting the classifier to the training set\")\n",
    "clf = MLPClassifier(hidden_layer_sizes=(nohn,), solver='sgd', activation='tanh', batch_size=250, verbose=True, \n",
    "                    early_stopping=True)\n",
    "clf.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "GpQlLK8wO-lw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.85      0.92      0.88        12\n",
      "         3.0       0.81      0.81      0.81        16\n",
      "         4.0       0.75      0.94      0.83        16\n",
      "         5.0       0.89      0.80      0.84        20\n",
      "         6.0       0.93      1.00      0.96        13\n",
      "         7.0       0.86      0.95      0.90        19\n",
      "         8.0       1.00      0.89      0.94        19\n",
      "         9.0       0.88      0.88      0.88        16\n",
      "        11.0       0.95      0.78      0.86        23\n",
      "        12.0       0.92      0.92      0.92        13\n",
      "        13.0       0.83      0.65      0.73        23\n",
      "        15.0       0.92      1.00      0.96        12\n",
      "        16.0       0.93      1.00      0.96        13\n",
      "        17.0       0.91      0.71      0.80        14\n",
      "        18.0       0.82      1.00      0.90        14\n",
      "        20.0       0.80      1.00      0.89        12\n",
      "        22.0       0.88      0.74      0.80        19\n",
      "        23.0       0.95      0.95      0.95        19\n",
      "        24.0       1.00      0.95      0.98        21\n",
      "        25.0       0.78      0.88      0.82        16\n",
      "        26.0       1.00      0.74      0.85        19\n",
      "        27.0       0.55      0.86      0.67         7\n",
      "        28.0       0.71      0.79      0.75        19\n",
      "        32.0       0.95      0.91      0.93        23\n",
      "        33.0       0.88      0.88      0.88        16\n",
      "        34.0       1.00      0.85      0.92        20\n",
      "        35.0       0.93      0.88      0.90        16\n",
      "        37.0       0.58      0.88      0.70         8\n",
      "        38.0       0.89      0.94      0.91        17\n",
      "        39.0       0.90      0.95      0.93        20\n",
      "\n",
      "    accuracy                           0.87       495\n",
      "   macro avg       0.87      0.88      0.87       495\n",
      "weighted avg       0.88      0.87      0.87       495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test_pca) # reoognises the test images \n",
    "print(classification_report(y_test, y_pred)) # the recognition accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 3.67746047\n",
      "Validation score: 0.024691\n",
      "Iteration 2, loss = 3.66663779\n",
      "Validation score: 0.024691\n",
      "Iteration 3, loss = 3.65002764\n",
      "Validation score: 0.024691\n",
      "Iteration 4, loss = 3.62933634\n",
      "Validation score: 0.037037\n",
      "Iteration 5, loss = 3.60565414\n",
      "Validation score: 0.037037\n",
      "Iteration 6, loss = 3.57957676\n",
      "Validation score: 0.049383\n",
      "Iteration 7, loss = 3.55211994\n",
      "Validation score: 0.049383\n",
      "Iteration 8, loss = 3.52355869\n",
      "Validation score: 0.049383\n",
      "Iteration 9, loss = 3.49423121\n",
      "Validation score: 0.049383\n",
      "Iteration 10, loss = 3.46436407\n",
      "Validation score: 0.049383\n",
      "Iteration 11, loss = 3.43418762\n",
      "Validation score: 0.049383\n",
      "Iteration 12, loss = 3.40372101\n",
      "Validation score: 0.061728\n",
      "Iteration 13, loss = 3.37325915\n",
      "Validation score: 0.074074\n",
      "Iteration 14, loss = 3.34261106\n",
      "Validation score: 0.074074\n",
      "Iteration 15, loss = 3.31200927\n",
      "Validation score: 0.086420\n",
      "Iteration 16, loss = 3.28142440\n",
      "Validation score: 0.086420\n",
      "Iteration 17, loss = 3.25112703\n",
      "Validation score: 0.086420\n",
      "Iteration 18, loss = 3.22060683\n",
      "Validation score: 0.086420\n",
      "Iteration 19, loss = 3.19024922\n",
      "Validation score: 0.086420\n",
      "Iteration 20, loss = 3.15999210\n",
      "Validation score: 0.086420\n",
      "Iteration 21, loss = 3.13000570\n",
      "Validation score: 0.111111\n",
      "Iteration 22, loss = 3.10013859\n",
      "Validation score: 0.123457\n",
      "Iteration 23, loss = 3.07024487\n",
      "Validation score: 0.123457\n",
      "Iteration 24, loss = 3.04061258\n",
      "Validation score: 0.123457\n",
      "Iteration 25, loss = 3.01104496\n",
      "Validation score: 0.135802\n",
      "Iteration 26, loss = 2.98171853\n",
      "Validation score: 0.160494\n",
      "Iteration 27, loss = 2.95233983\n",
      "Validation score: 0.185185\n",
      "Iteration 28, loss = 2.92317252\n",
      "Validation score: 0.197531\n",
      "Iteration 29, loss = 2.89437972\n",
      "Validation score: 0.197531\n",
      "Iteration 30, loss = 2.86546313\n",
      "Validation score: 0.209877\n",
      "Iteration 31, loss = 2.83699260\n",
      "Validation score: 0.209877\n",
      "Iteration 32, loss = 2.80855854\n",
      "Validation score: 0.222222\n",
      "Iteration 33, loss = 2.78019003\n",
      "Validation score: 0.246914\n",
      "Iteration 34, loss = 2.75216969\n",
      "Validation score: 0.271605\n",
      "Iteration 35, loss = 2.72402782\n",
      "Validation score: 0.283951\n",
      "Iteration 36, loss = 2.69615184\n",
      "Validation score: 0.283951\n",
      "Iteration 37, loss = 2.66856286\n",
      "Validation score: 0.283951\n",
      "Iteration 38, loss = 2.64114487\n",
      "Validation score: 0.283951\n",
      "Iteration 39, loss = 2.61395269\n",
      "Validation score: 0.296296\n",
      "Iteration 40, loss = 2.58683932\n",
      "Validation score: 0.296296\n",
      "Iteration 41, loss = 2.55989446\n",
      "Validation score: 0.308642\n",
      "Iteration 42, loss = 2.53313706\n",
      "Validation score: 0.320988\n",
      "Iteration 43, loss = 2.50656223\n",
      "Validation score: 0.333333\n",
      "Iteration 44, loss = 2.48005598\n",
      "Validation score: 0.333333\n",
      "Iteration 45, loss = 2.45403277\n",
      "Validation score: 0.333333\n",
      "Iteration 46, loss = 2.42800492\n",
      "Validation score: 0.358025\n",
      "Iteration 47, loss = 2.40210941\n",
      "Validation score: 0.382716\n",
      "Iteration 48, loss = 2.37656777\n",
      "Validation score: 0.395062\n",
      "Iteration 49, loss = 2.35114459\n",
      "Validation score: 0.407407\n",
      "Iteration 50, loss = 2.32587459\n",
      "Validation score: 0.407407\n",
      "Iteration 51, loss = 2.30085801\n",
      "Validation score: 0.432099\n",
      "Iteration 52, loss = 2.27597083\n",
      "Validation score: 0.444444\n",
      "Iteration 53, loss = 2.25141162\n",
      "Validation score: 0.444444\n",
      "Iteration 54, loss = 2.22697278\n",
      "Validation score: 0.444444\n",
      "Iteration 55, loss = 2.20262388\n",
      "Validation score: 0.444444\n",
      "Iteration 56, loss = 2.17871869\n",
      "Validation score: 0.444444\n",
      "Iteration 57, loss = 2.15484402\n",
      "Validation score: 0.456790\n",
      "Iteration 58, loss = 2.13127621\n",
      "Validation score: 0.469136\n",
      "Iteration 59, loss = 2.10777950\n",
      "Validation score: 0.469136\n",
      "Iteration 60, loss = 2.08471540\n",
      "Validation score: 0.481481\n",
      "Iteration 61, loss = 2.06161570\n",
      "Validation score: 0.481481\n",
      "Iteration 62, loss = 2.03881807\n",
      "Validation score: 0.481481\n",
      "Iteration 63, loss = 2.01630105\n",
      "Validation score: 0.506173\n",
      "Iteration 64, loss = 1.99396055\n",
      "Validation score: 0.506173\n",
      "Iteration 65, loss = 1.97172763\n",
      "Validation score: 0.518519\n",
      "Iteration 66, loss = 1.94982028\n",
      "Validation score: 0.518519\n",
      "Iteration 67, loss = 1.92818811\n",
      "Validation score: 0.530864\n",
      "Iteration 68, loss = 1.90666566\n",
      "Validation score: 0.543210\n",
      "Iteration 69, loss = 1.88539599\n",
      "Validation score: 0.543210\n",
      "Iteration 70, loss = 1.86421241\n",
      "Validation score: 0.543210\n",
      "Iteration 71, loss = 1.84344593\n",
      "Validation score: 0.543210\n",
      "Iteration 72, loss = 1.82277354\n",
      "Validation score: 0.543210\n",
      "Iteration 73, loss = 1.80233291\n",
      "Validation score: 0.555556\n",
      "Iteration 74, loss = 1.78221436\n",
      "Validation score: 0.555556\n",
      "Iteration 75, loss = 1.76204068\n",
      "Validation score: 0.555556\n",
      "Iteration 76, loss = 1.74236159\n",
      "Validation score: 0.555556\n",
      "Iteration 77, loss = 1.72275228\n",
      "Validation score: 0.555556\n",
      "Iteration 78, loss = 1.70347403\n",
      "Validation score: 0.567901\n",
      "Iteration 79, loss = 1.68426166\n",
      "Validation score: 0.567901\n",
      "Iteration 80, loss = 1.66532213\n",
      "Validation score: 0.567901\n",
      "Iteration 81, loss = 1.64651892\n",
      "Validation score: 0.592593\n",
      "Iteration 82, loss = 1.62804066\n",
      "Validation score: 0.592593\n",
      "Iteration 83, loss = 1.60978362\n",
      "Validation score: 0.592593\n",
      "Iteration 84, loss = 1.59165318\n",
      "Validation score: 0.604938\n",
      "Iteration 85, loss = 1.57381433\n",
      "Validation score: 0.604938\n",
      "Iteration 86, loss = 1.55599608\n",
      "Validation score: 0.604938\n",
      "Iteration 87, loss = 1.53869601\n",
      "Validation score: 0.604938\n",
      "Iteration 88, loss = 1.52138156\n",
      "Validation score: 0.617284\n",
      "Iteration 89, loss = 1.50424365\n",
      "Validation score: 0.617284\n",
      "Iteration 90, loss = 1.48743534\n",
      "Validation score: 0.617284\n",
      "Iteration 91, loss = 1.47074262\n",
      "Validation score: 0.629630\n",
      "Iteration 92, loss = 1.45431802\n",
      "Validation score: 0.641975\n",
      "Iteration 93, loss = 1.43800439\n",
      "Validation score: 0.641975\n",
      "Iteration 94, loss = 1.42190460\n",
      "Validation score: 0.641975\n",
      "Iteration 95, loss = 1.40613054\n",
      "Validation score: 0.641975\n",
      "Iteration 96, loss = 1.39044291\n",
      "Validation score: 0.641975\n",
      "Iteration 97, loss = 1.37497400\n",
      "Validation score: 0.654321\n",
      "Iteration 98, loss = 1.35962871\n",
      "Validation score: 0.654321\n",
      "Iteration 99, loss = 1.34453964\n",
      "Validation score: 0.666667\n",
      "Iteration 100, loss = 1.32959329\n",
      "Validation score: 0.666667\n",
      "Iteration 101, loss = 1.31482341\n",
      "Validation score: 0.679012\n",
      "Iteration 102, loss = 1.30027760\n",
      "Validation score: 0.679012\n",
      "Iteration 103, loss = 1.28596880\n",
      "Validation score: 0.691358\n",
      "Iteration 104, loss = 1.27173894\n",
      "Validation score: 0.691358\n",
      "Iteration 105, loss = 1.25776565\n",
      "Validation score: 0.703704\n",
      "Iteration 106, loss = 1.24394854\n",
      "Validation score: 0.703704\n",
      "Iteration 107, loss = 1.23031750\n",
      "Validation score: 0.703704\n",
      "Iteration 108, loss = 1.21687972\n",
      "Validation score: 0.703704\n",
      "Iteration 109, loss = 1.20343135\n",
      "Validation score: 0.703704\n",
      "Iteration 110, loss = 1.19035770\n",
      "Validation score: 0.703704\n",
      "Iteration 111, loss = 1.17745018\n",
      "Validation score: 0.703704\n",
      "Iteration 112, loss = 1.16458124\n",
      "Validation score: 0.703704\n",
      "Iteration 113, loss = 1.15201099\n",
      "Validation score: 0.703704\n",
      "Iteration 114, loss = 1.13947831\n",
      "Validation score: 0.703704\n",
      "Iteration 115, loss = 1.12725544\n",
      "Validation score: 0.703704\n",
      "Iteration 116, loss = 1.11497316\n",
      "Validation score: 0.703704\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 3.72425368\n",
      "Validation score: 0.061728\n",
      "Iteration 2, loss = 3.71303223\n",
      "Validation score: 0.061728\n",
      "Iteration 3, loss = 3.69561615\n",
      "Validation score: 0.061728\n",
      "Iteration 4, loss = 3.67402314\n",
      "Validation score: 0.061728\n",
      "Iteration 5, loss = 3.64918538\n",
      "Validation score: 0.074074\n",
      "Iteration 6, loss = 3.62217314\n",
      "Validation score: 0.086420\n",
      "Iteration 7, loss = 3.59353451\n",
      "Validation score: 0.086420\n",
      "Iteration 8, loss = 3.56380737\n",
      "Validation score: 0.086420\n",
      "Iteration 9, loss = 3.53320952\n",
      "Validation score: 0.086420\n",
      "Iteration 10, loss = 3.50220919\n",
      "Validation score: 0.086420\n",
      "Iteration 11, loss = 3.47068015\n",
      "Validation score: 0.086420\n",
      "Iteration 12, loss = 3.43902707\n",
      "Validation score: 0.086420\n",
      "Iteration 13, loss = 3.40725743\n",
      "Validation score: 0.086420\n",
      "Iteration 14, loss = 3.37530306\n",
      "Validation score: 0.098765\n",
      "Iteration 15, loss = 3.34358128\n",
      "Validation score: 0.098765\n",
      "Iteration 16, loss = 3.31173090\n",
      "Validation score: 0.098765\n",
      "Iteration 17, loss = 3.28006443\n",
      "Validation score: 0.098765\n",
      "Iteration 18, loss = 3.24840824\n",
      "Validation score: 0.098765\n",
      "Iteration 19, loss = 3.21711322\n",
      "Validation score: 0.098765\n",
      "Iteration 20, loss = 3.18552288\n",
      "Validation score: 0.111111\n",
      "Iteration 21, loss = 3.15442848\n",
      "Validation score: 0.123457\n",
      "Iteration 22, loss = 3.12320823\n",
      "Validation score: 0.135802\n",
      "Iteration 23, loss = 3.09233369\n",
      "Validation score: 0.148148\n",
      "Iteration 24, loss = 3.06168083\n",
      "Validation score: 0.148148\n",
      "Iteration 25, loss = 3.03094388\n",
      "Validation score: 0.148148\n",
      "Iteration 26, loss = 3.00055540\n",
      "Validation score: 0.148148\n",
      "Iteration 27, loss = 2.97030980\n",
      "Validation score: 0.148148\n",
      "Iteration 28, loss = 2.94000668\n",
      "Validation score: 0.160494\n",
      "Iteration 29, loss = 2.91006037\n",
      "Validation score: 0.197531\n",
      "Iteration 30, loss = 2.88037923\n",
      "Validation score: 0.209877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 31, loss = 2.85067010\n",
      "Validation score: 0.234568\n",
      "Iteration 32, loss = 2.82119335\n",
      "Validation score: 0.246914\n",
      "Iteration 33, loss = 2.79199379\n",
      "Validation score: 0.246914\n",
      "Iteration 34, loss = 2.76301892\n",
      "Validation score: 0.246914\n",
      "Iteration 35, loss = 2.73408270\n",
      "Validation score: 0.259259\n",
      "Iteration 36, loss = 2.70528730\n",
      "Validation score: 0.271605\n",
      "Iteration 37, loss = 2.67684219\n",
      "Validation score: 0.283951\n",
      "Iteration 38, loss = 2.64849634\n",
      "Validation score: 0.283951\n",
      "Iteration 39, loss = 2.62034632\n",
      "Validation score: 0.308642\n",
      "Iteration 40, loss = 2.59247930\n",
      "Validation score: 0.308642\n",
      "Iteration 41, loss = 2.56468200\n",
      "Validation score: 0.308642\n",
      "Iteration 42, loss = 2.53720380\n",
      "Validation score: 0.308642\n",
      "Iteration 43, loss = 2.50988549\n",
      "Validation score: 0.308642\n",
      "Iteration 44, loss = 2.48273603\n",
      "Validation score: 0.320988\n",
      "Iteration 45, loss = 2.45590391\n",
      "Validation score: 0.333333\n",
      "Iteration 46, loss = 2.42905384\n",
      "Validation score: 0.333333\n",
      "Iteration 47, loss = 2.40257182\n",
      "Validation score: 0.345679\n",
      "Iteration 48, loss = 2.37613101\n",
      "Validation score: 0.370370\n",
      "Iteration 49, loss = 2.35021684\n",
      "Validation score: 0.370370\n",
      "Iteration 50, loss = 2.32430245\n",
      "Validation score: 0.370370\n",
      "Iteration 51, loss = 2.29875397\n",
      "Validation score: 0.370370\n",
      "Iteration 52, loss = 2.27318145\n",
      "Validation score: 0.382716\n",
      "Iteration 53, loss = 2.24801368\n",
      "Validation score: 0.395062\n",
      "Iteration 54, loss = 2.22287107\n",
      "Validation score: 0.407407\n",
      "Iteration 55, loss = 2.19828472\n",
      "Validation score: 0.419753\n",
      "Iteration 56, loss = 2.17370406\n",
      "Validation score: 0.419753\n",
      "Iteration 57, loss = 2.14935822\n",
      "Validation score: 0.419753\n",
      "Iteration 58, loss = 2.12522631\n",
      "Validation score: 0.419753\n",
      "Iteration 59, loss = 2.10133377\n",
      "Validation score: 0.432099\n",
      "Iteration 60, loss = 2.07783459\n",
      "Validation score: 0.432099\n",
      "Iteration 61, loss = 2.05432427\n",
      "Validation score: 0.432099\n",
      "Iteration 62, loss = 2.03110783\n",
      "Validation score: 0.432099\n",
      "Iteration 63, loss = 2.00824049\n",
      "Validation score: 0.432099\n",
      "Iteration 64, loss = 1.98554770\n",
      "Validation score: 0.432099\n",
      "Iteration 65, loss = 1.96304377\n",
      "Validation score: 0.432099\n",
      "Iteration 66, loss = 1.94082823\n",
      "Validation score: 0.432099\n",
      "Iteration 67, loss = 1.91866577\n",
      "Validation score: 0.432099\n",
      "Iteration 68, loss = 1.89701207\n",
      "Validation score: 0.444444\n",
      "Iteration 69, loss = 1.87539332\n",
      "Validation score: 0.444444\n",
      "Iteration 70, loss = 1.85410026\n",
      "Validation score: 0.444444\n",
      "Iteration 71, loss = 1.83303507\n",
      "Validation score: 0.444444\n",
      "Iteration 72, loss = 1.81218338\n",
      "Validation score: 0.444444\n",
      "Iteration 73, loss = 1.79152533\n",
      "Validation score: 0.456790\n",
      "Iteration 74, loss = 1.77112708\n",
      "Validation score: 0.456790\n",
      "Iteration 75, loss = 1.75092672\n",
      "Validation score: 0.469136\n",
      "Iteration 76, loss = 1.73107134\n",
      "Validation score: 0.469136\n",
      "Iteration 77, loss = 1.71135971\n",
      "Validation score: 0.469136\n",
      "Iteration 78, loss = 1.69187109\n",
      "Validation score: 0.469136\n",
      "Iteration 79, loss = 1.67267813\n",
      "Validation score: 0.481481\n",
      "Iteration 80, loss = 1.65363384\n",
      "Validation score: 0.481481\n",
      "Iteration 81, loss = 1.63481258\n",
      "Validation score: 0.481481\n",
      "Iteration 82, loss = 1.61635269\n",
      "Validation score: 0.506173\n",
      "Iteration 83, loss = 1.59790923\n",
      "Validation score: 0.518519\n",
      "Iteration 84, loss = 1.57975833\n",
      "Validation score: 0.530864\n",
      "Iteration 85, loss = 1.56185286\n",
      "Validation score: 0.543210\n",
      "Iteration 86, loss = 1.54423075\n",
      "Validation score: 0.543210\n",
      "Iteration 87, loss = 1.52675102\n",
      "Validation score: 0.543210\n",
      "Iteration 88, loss = 1.50955894\n",
      "Validation score: 0.555556\n",
      "Iteration 89, loss = 1.49236800\n",
      "Validation score: 0.555556\n",
      "Iteration 90, loss = 1.47561757\n",
      "Validation score: 0.555556\n",
      "Iteration 91, loss = 1.45903013\n",
      "Validation score: 0.555556\n",
      "Iteration 92, loss = 1.44261831\n",
      "Validation score: 0.555556\n",
      "Iteration 93, loss = 1.42641908\n",
      "Validation score: 0.555556\n",
      "Iteration 94, loss = 1.41040302\n",
      "Validation score: 0.567901\n",
      "Iteration 95, loss = 1.39461265\n",
      "Validation score: 0.567901\n",
      "Iteration 96, loss = 1.37906574\n",
      "Validation score: 0.580247\n",
      "Iteration 97, loss = 1.36367645\n",
      "Validation score: 0.580247\n",
      "Iteration 98, loss = 1.34845716\n",
      "Validation score: 0.580247\n",
      "Iteration 99, loss = 1.33340819\n",
      "Validation score: 0.580247\n",
      "Iteration 100, loss = 1.31875329\n",
      "Validation score: 0.580247\n",
      "Iteration 101, loss = 1.30415376\n",
      "Validation score: 0.592593\n",
      "Iteration 102, loss = 1.28965970\n",
      "Validation score: 0.604938\n",
      "Iteration 103, loss = 1.27552548\n",
      "Validation score: 0.617284\n",
      "Iteration 104, loss = 1.26143272\n",
      "Validation score: 0.617284\n",
      "Iteration 105, loss = 1.24755871\n",
      "Validation score: 0.629630\n",
      "Iteration 106, loss = 1.23385801\n",
      "Validation score: 0.629630\n",
      "Iteration 107, loss = 1.22043860\n",
      "Validation score: 0.629630\n",
      "Iteration 108, loss = 1.20707743\n",
      "Validation score: 0.629630\n",
      "Iteration 109, loss = 1.19390172\n",
      "Validation score: 0.629630\n",
      "Iteration 110, loss = 1.18096634\n",
      "Validation score: 0.641975\n",
      "Iteration 111, loss = 1.16818766\n",
      "Validation score: 0.654321\n",
      "Iteration 112, loss = 1.15560485\n",
      "Validation score: 0.654321\n",
      "Iteration 113, loss = 1.14310743\n",
      "Validation score: 0.654321\n",
      "Iteration 114, loss = 1.13084373\n",
      "Validation score: 0.666667\n",
      "Iteration 115, loss = 1.11869189\n",
      "Validation score: 0.666667\n",
      "Iteration 116, loss = 1.10669521\n",
      "Validation score: 0.679012\n",
      "Iteration 117, loss = 1.09496435\n",
      "Validation score: 0.691358\n",
      "Iteration 118, loss = 1.08322537\n",
      "Validation score: 0.691358\n",
      "Iteration 119, loss = 1.07187290\n",
      "Validation score: 0.691358\n",
      "Iteration 120, loss = 1.06039606\n",
      "Validation score: 0.691358\n",
      "Iteration 121, loss = 1.04931193\n",
      "Validation score: 0.691358\n",
      "Iteration 122, loss = 1.03824330\n",
      "Validation score: 0.703704\n",
      "Iteration 123, loss = 1.02732351\n",
      "Validation score: 0.703704\n",
      "Iteration 124, loss = 1.01656922\n",
      "Validation score: 0.716049\n",
      "Iteration 125, loss = 1.00599377\n",
      "Validation score: 0.716049\n",
      "Iteration 126, loss = 0.99543780\n",
      "Validation score: 0.716049\n",
      "Iteration 127, loss = 0.98518311\n",
      "Validation score: 0.716049\n",
      "Iteration 128, loss = 0.97495565\n",
      "Validation score: 0.716049\n",
      "Iteration 129, loss = 0.96494887\n",
      "Validation score: 0.716049\n",
      "Iteration 130, loss = 0.95486305\n",
      "Validation score: 0.716049\n",
      "Iteration 131, loss = 0.94524988\n",
      "Validation score: 0.716049\n",
      "Iteration 132, loss = 0.93556702\n",
      "Validation score: 0.716049\n",
      "Iteration 133, loss = 0.92605384\n",
      "Validation score: 0.716049\n",
      "Iteration 134, loss = 0.91658574\n",
      "Validation score: 0.716049\n",
      "Iteration 135, loss = 0.90726542\n",
      "Validation score: 0.716049\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 3.67430473\n",
      "Validation score: 0.037037\n",
      "Iteration 2, loss = 3.66347161\n",
      "Validation score: 0.049383\n",
      "Iteration 3, loss = 3.64702153\n",
      "Validation score: 0.049383\n",
      "Iteration 4, loss = 3.62648111\n",
      "Validation score: 0.049383\n",
      "Iteration 5, loss = 3.60282195\n",
      "Validation score: 0.049383\n",
      "Iteration 6, loss = 3.57707838\n",
      "Validation score: 0.049383\n",
      "Iteration 7, loss = 3.54977376\n",
      "Validation score: 0.074074\n",
      "Iteration 8, loss = 3.52131625\n",
      "Validation score: 0.074074\n",
      "Iteration 9, loss = 3.49213372\n",
      "Validation score: 0.074074\n",
      "Iteration 10, loss = 3.46263670\n",
      "Validation score: 0.098765\n",
      "Iteration 11, loss = 3.43264038\n",
      "Validation score: 0.098765\n",
      "Iteration 12, loss = 3.40229670\n",
      "Validation score: 0.098765\n",
      "Iteration 13, loss = 3.37181947\n",
      "Validation score: 0.098765\n",
      "Iteration 14, loss = 3.34188002\n",
      "Validation score: 0.098765\n",
      "Iteration 15, loss = 3.31128168\n",
      "Validation score: 0.098765\n",
      "Iteration 16, loss = 3.28091970\n",
      "Validation score: 0.098765\n",
      "Iteration 17, loss = 3.25076894\n",
      "Validation score: 0.098765\n",
      "Iteration 18, loss = 3.22054498\n",
      "Validation score: 0.098765\n",
      "Iteration 19, loss = 3.19048694\n",
      "Validation score: 0.098765\n",
      "Iteration 20, loss = 3.16041432\n",
      "Validation score: 0.098765\n",
      "Iteration 21, loss = 3.13068439\n",
      "Validation score: 0.098765\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 3.65204662\n",
      "Validation score: 0.049383\n",
      "Iteration 2, loss = 3.64096958\n",
      "Validation score: 0.049383\n",
      "Iteration 3, loss = 3.62411006\n",
      "Validation score: 0.049383\n",
      "Iteration 4, loss = 3.60281539\n",
      "Validation score: 0.049383\n",
      "Iteration 5, loss = 3.57843380\n",
      "Validation score: 0.049383\n",
      "Iteration 6, loss = 3.55202193\n",
      "Validation score: 0.049383\n",
      "Iteration 7, loss = 3.52372249\n",
      "Validation score: 0.049383\n",
      "Iteration 8, loss = 3.49455100\n",
      "Validation score: 0.049383\n",
      "Iteration 9, loss = 3.46457847\n",
      "Validation score: 0.061728\n",
      "Iteration 10, loss = 3.43415438\n",
      "Validation score: 0.061728\n",
      "Iteration 11, loss = 3.40317968\n",
      "Validation score: 0.061728\n",
      "Iteration 12, loss = 3.37202096\n",
      "Validation score: 0.061728\n",
      "Iteration 13, loss = 3.34093146\n",
      "Validation score: 0.061728\n",
      "Iteration 14, loss = 3.30971766\n",
      "Validation score: 0.061728\n",
      "Iteration 15, loss = 3.27837989\n",
      "Validation score: 0.061728\n",
      "Iteration 16, loss = 3.24719412\n",
      "Validation score: 0.074074\n",
      "Iteration 17, loss = 3.21596086\n",
      "Validation score: 0.086420\n",
      "Iteration 18, loss = 3.18506946\n",
      "Validation score: 0.086420\n",
      "Iteration 19, loss = 3.15406297\n",
      "Validation score: 0.098765\n",
      "Iteration 20, loss = 3.12329431\n",
      "Validation score: 0.098765\n",
      "Iteration 21, loss = 3.09276597\n",
      "Validation score: 0.111111\n",
      "Iteration 22, loss = 3.06213079\n",
      "Validation score: 0.123457\n",
      "Iteration 23, loss = 3.03171970\n",
      "Validation score: 0.123457\n",
      "Iteration 24, loss = 3.00141621\n",
      "Validation score: 0.148148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 25, loss = 2.97120569\n",
      "Validation score: 0.160494\n",
      "Iteration 26, loss = 2.94143832\n",
      "Validation score: 0.172840\n",
      "Iteration 27, loss = 2.91162706\n",
      "Validation score: 0.172840\n",
      "Iteration 28, loss = 2.88205319\n",
      "Validation score: 0.172840\n",
      "Iteration 29, loss = 2.85250649\n",
      "Validation score: 0.185185\n",
      "Iteration 30, loss = 2.82341361\n",
      "Validation score: 0.185185\n",
      "Iteration 31, loss = 2.79418819\n",
      "Validation score: 0.185185\n",
      "Iteration 32, loss = 2.76533777\n",
      "Validation score: 0.185185\n",
      "Iteration 33, loss = 2.73648571\n",
      "Validation score: 0.185185\n",
      "Iteration 34, loss = 2.70795253\n",
      "Validation score: 0.197531\n",
      "Iteration 35, loss = 2.67957935\n",
      "Validation score: 0.209877\n",
      "Iteration 36, loss = 2.65130666\n",
      "Validation score: 0.209877\n",
      "Iteration 37, loss = 2.62318088\n",
      "Validation score: 0.209877\n",
      "Iteration 38, loss = 2.59551236\n",
      "Validation score: 0.222222\n",
      "Iteration 39, loss = 2.56780275\n",
      "Validation score: 0.222222\n",
      "Iteration 40, loss = 2.54028643\n",
      "Validation score: 0.222222\n",
      "Iteration 41, loss = 2.51310853\n",
      "Validation score: 0.259259\n",
      "Iteration 42, loss = 2.48599828\n",
      "Validation score: 0.259259\n",
      "Iteration 43, loss = 2.45920795\n",
      "Validation score: 0.259259\n",
      "Iteration 44, loss = 2.43238822\n",
      "Validation score: 0.271605\n",
      "Iteration 45, loss = 2.40604868\n",
      "Validation score: 0.283951\n",
      "Iteration 46, loss = 2.37973240\n",
      "Validation score: 0.283951\n",
      "Iteration 47, loss = 2.35364762\n",
      "Validation score: 0.308642\n",
      "Iteration 48, loss = 2.32777761\n",
      "Validation score: 0.320988\n",
      "Iteration 49, loss = 2.30220462\n",
      "Validation score: 0.345679\n",
      "Iteration 50, loss = 2.27674557\n",
      "Validation score: 0.345679\n",
      "Iteration 51, loss = 2.25136594\n",
      "Validation score: 0.370370\n",
      "Iteration 52, loss = 2.22653375\n",
      "Validation score: 0.382716\n",
      "Iteration 53, loss = 2.20181991\n",
      "Validation score: 0.382716\n",
      "Iteration 54, loss = 2.17707546\n",
      "Validation score: 0.407407\n",
      "Iteration 55, loss = 2.15279066\n",
      "Validation score: 0.432099\n",
      "Iteration 56, loss = 2.12869466\n",
      "Validation score: 0.432099\n",
      "Iteration 57, loss = 2.10468915\n",
      "Validation score: 0.432099\n",
      "Iteration 58, loss = 2.08095344\n",
      "Validation score: 0.432099\n",
      "Iteration 59, loss = 2.05771793\n",
      "Validation score: 0.444444\n",
      "Iteration 60, loss = 2.03442248\n",
      "Validation score: 0.456790\n",
      "Iteration 61, loss = 2.01129376\n",
      "Validation score: 0.456790\n",
      "Iteration 62, loss = 1.98860840\n",
      "Validation score: 0.456790\n",
      "Iteration 63, loss = 1.96590359\n",
      "Validation score: 0.456790\n",
      "Iteration 64, loss = 1.94363276\n",
      "Validation score: 0.456790\n",
      "Iteration 65, loss = 1.92150007\n",
      "Validation score: 0.456790\n",
      "Iteration 66, loss = 1.89958445\n",
      "Validation score: 0.456790\n",
      "Iteration 67, loss = 1.87803560\n",
      "Validation score: 0.456790\n",
      "Iteration 68, loss = 1.85652967\n",
      "Validation score: 0.456790\n",
      "Iteration 69, loss = 1.83537188\n",
      "Validation score: 0.456790\n",
      "Iteration 70, loss = 1.81431876\n",
      "Validation score: 0.469136\n",
      "Iteration 71, loss = 1.79363894\n",
      "Validation score: 0.469136\n",
      "Iteration 72, loss = 1.77303100\n",
      "Validation score: 0.469136\n",
      "Iteration 73, loss = 1.75268856\n",
      "Validation score: 0.469136\n",
      "Iteration 74, loss = 1.73281565\n",
      "Validation score: 0.481481\n",
      "Iteration 75, loss = 1.71285191\n",
      "Validation score: 0.481481\n",
      "Iteration 76, loss = 1.69323805\n",
      "Validation score: 0.506173\n",
      "Iteration 77, loss = 1.67387287\n",
      "Validation score: 0.506173\n",
      "Iteration 78, loss = 1.65463306\n",
      "Validation score: 0.506173\n",
      "Iteration 79, loss = 1.63562588\n",
      "Validation score: 0.506173\n",
      "Iteration 80, loss = 1.61702192\n",
      "Validation score: 0.506173\n",
      "Iteration 81, loss = 1.59847610\n",
      "Validation score: 0.506173\n",
      "Iteration 82, loss = 1.58014326\n",
      "Validation score: 0.506173\n",
      "Iteration 83, loss = 1.56209497\n",
      "Validation score: 0.518519\n",
      "Iteration 84, loss = 1.54422105\n",
      "Validation score: 0.518519\n",
      "Iteration 85, loss = 1.52655366\n",
      "Validation score: 0.530864\n",
      "Iteration 86, loss = 1.50915770\n",
      "Validation score: 0.530864\n",
      "Iteration 87, loss = 1.49189403\n",
      "Validation score: 0.530864\n",
      "Iteration 88, loss = 1.47491074\n",
      "Validation score: 0.530864\n",
      "Iteration 89, loss = 1.45807823\n",
      "Validation score: 0.530864\n",
      "Iteration 90, loss = 1.44147289\n",
      "Validation score: 0.530864\n",
      "Iteration 91, loss = 1.42518188\n",
      "Validation score: 0.543210\n",
      "Iteration 92, loss = 1.40888811\n",
      "Validation score: 0.555556\n",
      "Iteration 93, loss = 1.39289137\n",
      "Validation score: 0.567901\n",
      "Iteration 94, loss = 1.37712379\n",
      "Validation score: 0.580247\n",
      "Iteration 95, loss = 1.36154026\n",
      "Validation score: 0.580247\n",
      "Iteration 96, loss = 1.34610563\n",
      "Validation score: 0.592593\n",
      "Iteration 97, loss = 1.33105295\n",
      "Validation score: 0.592593\n",
      "Iteration 98, loss = 1.31595681\n",
      "Validation score: 0.592593\n",
      "Iteration 99, loss = 1.30120144\n",
      "Validation score: 0.592593\n",
      "Iteration 100, loss = 1.28650781\n",
      "Validation score: 0.592593\n",
      "Iteration 101, loss = 1.27207344\n",
      "Validation score: 0.592593\n",
      "Iteration 102, loss = 1.25782141\n",
      "Validation score: 0.604938\n",
      "Iteration 103, loss = 1.24376272\n",
      "Validation score: 0.617284\n",
      "Iteration 104, loss = 1.22998696\n",
      "Validation score: 0.617284\n",
      "Iteration 105, loss = 1.21613011\n",
      "Validation score: 0.617284\n",
      "Iteration 106, loss = 1.20266584\n",
      "Validation score: 0.617284\n",
      "Iteration 107, loss = 1.18932032\n",
      "Validation score: 0.629630\n",
      "Iteration 108, loss = 1.17615364\n",
      "Validation score: 0.629630\n",
      "Iteration 109, loss = 1.16315803\n",
      "Validation score: 0.629630\n",
      "Iteration 110, loss = 1.15025670\n",
      "Validation score: 0.629630\n",
      "Iteration 111, loss = 1.13759715\n",
      "Validation score: 0.629630\n",
      "Iteration 112, loss = 1.12509867\n",
      "Validation score: 0.629630\n",
      "Iteration 113, loss = 1.11277427\n",
      "Validation score: 0.629630\n",
      "Iteration 114, loss = 1.10071262\n",
      "Validation score: 0.629630\n",
      "Iteration 115, loss = 1.08861095\n",
      "Validation score: 0.641975\n",
      "Iteration 116, loss = 1.07675059\n",
      "Validation score: 0.654321\n",
      "Iteration 117, loss = 1.06504321\n",
      "Validation score: 0.666667\n",
      "Iteration 118, loss = 1.05341958\n",
      "Validation score: 0.666667\n",
      "Iteration 119, loss = 1.04209934\n",
      "Validation score: 0.666667\n",
      "Iteration 120, loss = 1.03083647\n",
      "Validation score: 0.666667\n",
      "Iteration 121, loss = 1.01976785\n",
      "Validation score: 0.666667\n",
      "Iteration 122, loss = 1.00874855\n",
      "Validation score: 0.666667\n",
      "Iteration 123, loss = 0.99803194\n",
      "Validation score: 0.666667\n",
      "Iteration 124, loss = 0.98734308\n",
      "Validation score: 0.666667\n",
      "Iteration 125, loss = 0.97686067\n",
      "Validation score: 0.666667\n",
      "Iteration 126, loss = 0.96644657\n",
      "Validation score: 0.666667\n",
      "Iteration 127, loss = 0.95618151\n",
      "Validation score: 0.666667\n",
      "Iteration 128, loss = 0.94612722\n",
      "Validation score: 0.679012\n",
      "Iteration 129, loss = 0.93609031\n",
      "Validation score: 0.679012\n",
      "Iteration 130, loss = 0.92629022\n",
      "Validation score: 0.679012\n",
      "Iteration 131, loss = 0.91663229\n",
      "Validation score: 0.679012\n",
      "Iteration 132, loss = 0.90697087\n",
      "Validation score: 0.679012\n",
      "Iteration 133, loss = 0.89749578\n",
      "Validation score: 0.679012\n",
      "Iteration 134, loss = 0.88824699\n",
      "Validation score: 0.691358\n",
      "Iteration 135, loss = 0.87896251\n",
      "Validation score: 0.703704\n",
      "Iteration 136, loss = 0.86988105\n",
      "Validation score: 0.716049\n",
      "Iteration 137, loss = 0.86099022\n",
      "Validation score: 0.716049\n",
      "Iteration 138, loss = 0.85214452\n",
      "Validation score: 0.716049\n",
      "Iteration 139, loss = 0.84336812\n",
      "Validation score: 0.716049\n",
      "Iteration 140, loss = 0.83476571\n",
      "Validation score: 0.728395\n",
      "Iteration 141, loss = 0.82627485\n",
      "Validation score: 0.728395\n",
      "Iteration 142, loss = 0.81787138\n",
      "Validation score: 0.728395\n",
      "Iteration 143, loss = 0.80969019\n",
      "Validation score: 0.728395\n",
      "Iteration 144, loss = 0.80147834\n",
      "Validation score: 0.728395\n",
      "Iteration 145, loss = 0.79341031\n",
      "Validation score: 0.728395\n",
      "Iteration 146, loss = 0.78547798\n",
      "Validation score: 0.728395\n",
      "Iteration 147, loss = 0.77759713\n",
      "Validation score: 0.740741\n",
      "Iteration 148, loss = 0.76989161\n",
      "Validation score: 0.740741\n",
      "Iteration 149, loss = 0.76222912\n",
      "Validation score: 0.753086\n",
      "Iteration 150, loss = 0.75471870\n",
      "Validation score: 0.753086\n",
      "Iteration 151, loss = 0.74727961\n",
      "Validation score: 0.753086\n",
      "Iteration 152, loss = 0.73988525\n",
      "Validation score: 0.753086\n",
      "Iteration 153, loss = 0.73268846\n",
      "Validation score: 0.753086\n",
      "Iteration 154, loss = 0.72554247\n",
      "Validation score: 0.753086\n",
      "Iteration 155, loss = 0.71846203\n",
      "Validation score: 0.753086\n",
      "Iteration 156, loss = 0.71152103\n",
      "Validation score: 0.753086\n",
      "Iteration 157, loss = 0.70464039\n",
      "Validation score: 0.753086\n",
      "Iteration 158, loss = 0.69784517\n",
      "Validation score: 0.753086\n",
      "Iteration 159, loss = 0.69115657\n",
      "Validation score: 0.753086\n",
      "Iteration 160, loss = 0.68458810\n",
      "Validation score: 0.753086\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 3.71089189\n",
      "Validation score: 0.061728\n",
      "Iteration 2, loss = 3.69975577\n",
      "Validation score: 0.061728\n",
      "Iteration 3, loss = 3.68270011\n",
      "Validation score: 0.061728\n",
      "Iteration 4, loss = 3.66142781\n",
      "Validation score: 0.061728\n",
      "Iteration 5, loss = 3.63703615\n",
      "Validation score: 0.061728\n",
      "Iteration 6, loss = 3.61025833\n",
      "Validation score: 0.061728\n",
      "Iteration 7, loss = 3.58215679\n",
      "Validation score: 0.061728\n",
      "Iteration 8, loss = 3.55287780\n",
      "Validation score: 0.061728\n",
      "Iteration 9, loss = 3.52262775\n",
      "Validation score: 0.061728\n",
      "Iteration 10, loss = 3.49197175\n",
      "Validation score: 0.074074\n",
      "Iteration 11, loss = 3.46085915\n",
      "Validation score: 0.086420\n",
      "Iteration 12, loss = 3.42973072\n",
      "Validation score: 0.098765\n",
      "Iteration 13, loss = 3.39822999\n",
      "Validation score: 0.098765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14, loss = 3.36702636\n",
      "Validation score: 0.111111\n",
      "Iteration 15, loss = 3.33552149\n",
      "Validation score: 0.111111\n",
      "Iteration 16, loss = 3.30427599\n",
      "Validation score: 0.135802\n",
      "Iteration 17, loss = 3.27291884\n",
      "Validation score: 0.135802\n",
      "Iteration 18, loss = 3.24184088\n",
      "Validation score: 0.135802\n",
      "Iteration 19, loss = 3.21077619\n",
      "Validation score: 0.135802\n",
      "Iteration 20, loss = 3.17956613\n",
      "Validation score: 0.135802\n",
      "Iteration 21, loss = 3.14872701\n",
      "Validation score: 0.135802\n",
      "Iteration 22, loss = 3.11801072\n",
      "Validation score: 0.135802\n",
      "Iteration 23, loss = 3.08725677\n",
      "Validation score: 0.135802\n",
      "Iteration 24, loss = 3.05699625\n",
      "Validation score: 0.160494\n",
      "Iteration 25, loss = 3.02693715\n",
      "Validation score: 0.197531\n",
      "Iteration 26, loss = 2.99663148\n",
      "Validation score: 0.209877\n",
      "Iteration 27, loss = 2.96659686\n",
      "Validation score: 0.209877\n",
      "Iteration 28, loss = 2.93676828\n",
      "Validation score: 0.209877\n",
      "Iteration 29, loss = 2.90711016\n",
      "Validation score: 0.209877\n",
      "Iteration 30, loss = 2.87756989\n",
      "Validation score: 0.234568\n",
      "Iteration 31, loss = 2.84816212\n",
      "Validation score: 0.234568\n",
      "Iteration 32, loss = 2.81903606\n",
      "Validation score: 0.234568\n",
      "Iteration 33, loss = 2.78994870\n",
      "Validation score: 0.234568\n",
      "Iteration 34, loss = 2.76126357\n",
      "Validation score: 0.246914\n",
      "Iteration 35, loss = 2.73251121\n",
      "Validation score: 0.271605\n",
      "Iteration 36, loss = 2.70391289\n",
      "Validation score: 0.283951\n",
      "Iteration 37, loss = 2.67568786\n",
      "Validation score: 0.283951\n",
      "Iteration 38, loss = 2.64740744\n",
      "Validation score: 0.296296\n",
      "Iteration 39, loss = 2.61939424\n",
      "Validation score: 0.296296\n",
      "Iteration 40, loss = 2.59168081\n",
      "Validation score: 0.296296\n",
      "Iteration 41, loss = 2.56398281\n",
      "Validation score: 0.320988\n",
      "Iteration 42, loss = 2.53659236\n",
      "Validation score: 0.345679\n",
      "Iteration 43, loss = 2.50936541\n",
      "Validation score: 0.358025\n",
      "Iteration 44, loss = 2.48227245\n",
      "Validation score: 0.370370\n",
      "Iteration 45, loss = 2.45553700\n",
      "Validation score: 0.382716\n",
      "Iteration 46, loss = 2.42877342\n",
      "Validation score: 0.395062\n",
      "Iteration 47, loss = 2.40242935\n",
      "Validation score: 0.407407\n",
      "Iteration 48, loss = 2.37608793\n",
      "Validation score: 0.407407\n",
      "Iteration 49, loss = 2.35002187\n",
      "Validation score: 0.432099\n",
      "Iteration 50, loss = 2.32415019\n",
      "Validation score: 0.432099\n",
      "Iteration 51, loss = 2.29850042\n",
      "Validation score: 0.432099\n",
      "Iteration 52, loss = 2.27310112\n",
      "Validation score: 0.432099\n",
      "Iteration 53, loss = 2.24777925\n",
      "Validation score: 0.432099\n",
      "Iteration 54, loss = 2.22267067\n",
      "Validation score: 0.469136\n",
      "Iteration 55, loss = 2.19795740\n",
      "Validation score: 0.481481\n",
      "Iteration 56, loss = 2.17336958\n",
      "Validation score: 0.493827\n",
      "Iteration 57, loss = 2.14893177\n",
      "Validation score: 0.493827\n",
      "Iteration 58, loss = 2.12467506\n",
      "Validation score: 0.493827\n",
      "Iteration 59, loss = 2.10092701\n",
      "Validation score: 0.493827\n",
      "Iteration 60, loss = 2.07711419\n",
      "Validation score: 0.506173\n",
      "Iteration 61, loss = 2.05357797\n",
      "Validation score: 0.518519\n",
      "Iteration 62, loss = 2.03034535\n",
      "Validation score: 0.518519\n",
      "Iteration 63, loss = 2.00708658\n",
      "Validation score: 0.518519\n",
      "Iteration 64, loss = 1.98437105\n",
      "Validation score: 0.518519\n",
      "Iteration 65, loss = 1.96167678\n",
      "Validation score: 0.518519\n",
      "Iteration 66, loss = 1.93929505\n",
      "Validation score: 0.530864\n",
      "Iteration 67, loss = 1.91716446\n",
      "Validation score: 0.530864\n",
      "Iteration 68, loss = 1.89519736\n",
      "Validation score: 0.543210\n",
      "Iteration 69, loss = 1.87346342\n",
      "Validation score: 0.543210\n",
      "Iteration 70, loss = 1.85207520\n",
      "Validation score: 0.555556\n",
      "Iteration 71, loss = 1.83077488\n",
      "Validation score: 0.567901\n",
      "Iteration 72, loss = 1.80969961\n",
      "Validation score: 0.580247\n",
      "Iteration 73, loss = 1.78892936\n",
      "Validation score: 0.580247\n",
      "Iteration 74, loss = 1.76826832\n",
      "Validation score: 0.592593\n",
      "Iteration 75, loss = 1.74799472\n",
      "Validation score: 0.592593\n",
      "Iteration 76, loss = 1.72791441\n",
      "Validation score: 0.604938\n",
      "Iteration 77, loss = 1.70809253\n",
      "Validation score: 0.604938\n",
      "Iteration 78, loss = 1.68832995\n",
      "Validation score: 0.617284\n",
      "Iteration 79, loss = 1.66901020\n",
      "Validation score: 0.629630\n",
      "Iteration 80, loss = 1.64969876\n",
      "Validation score: 0.629630\n",
      "Iteration 81, loss = 1.63076349\n",
      "Validation score: 0.629630\n",
      "Iteration 82, loss = 1.61195616\n",
      "Validation score: 0.629630\n",
      "Iteration 83, loss = 1.59338425\n",
      "Validation score: 0.641975\n",
      "Iteration 84, loss = 1.57512629\n",
      "Validation score: 0.641975\n",
      "Iteration 85, loss = 1.55698388\n",
      "Validation score: 0.641975\n",
      "Iteration 86, loss = 1.53923770\n",
      "Validation score: 0.641975\n",
      "Iteration 87, loss = 1.52153412\n",
      "Validation score: 0.641975\n",
      "Iteration 88, loss = 1.50405382\n",
      "Validation score: 0.641975\n",
      "Iteration 89, loss = 1.48683083\n",
      "Validation score: 0.654321\n",
      "Iteration 90, loss = 1.46995629\n",
      "Validation score: 0.654321\n",
      "Iteration 91, loss = 1.45316939\n",
      "Validation score: 0.666667\n",
      "Iteration 92, loss = 1.43651807\n",
      "Validation score: 0.666667\n",
      "Iteration 93, loss = 1.42020518\n",
      "Validation score: 0.679012\n",
      "Iteration 94, loss = 1.40401330\n",
      "Validation score: 0.679012\n",
      "Iteration 95, loss = 1.38811118\n",
      "Validation score: 0.679012\n",
      "Iteration 96, loss = 1.37236229\n",
      "Validation score: 0.679012\n",
      "Iteration 97, loss = 1.35676053\n",
      "Validation score: 0.703704\n",
      "Iteration 98, loss = 1.34146427\n",
      "Validation score: 0.716049\n",
      "Iteration 99, loss = 1.32632701\n",
      "Validation score: 0.716049\n",
      "Iteration 100, loss = 1.31134117\n",
      "Validation score: 0.716049\n",
      "Iteration 101, loss = 1.29668417\n",
      "Validation score: 0.716049\n",
      "Iteration 102, loss = 1.28211839\n",
      "Validation score: 0.716049\n",
      "Iteration 103, loss = 1.26773139\n",
      "Validation score: 0.716049\n",
      "Iteration 104, loss = 1.25358284\n",
      "Validation score: 0.716049\n",
      "Iteration 105, loss = 1.23952221\n",
      "Validation score: 0.716049\n",
      "Iteration 106, loss = 1.22578038\n",
      "Validation score: 0.716049\n",
      "Iteration 107, loss = 1.21223864\n",
      "Validation score: 0.716049\n",
      "Iteration 108, loss = 1.19872398\n",
      "Validation score: 0.728395\n",
      "Iteration 109, loss = 1.18541488\n",
      "Validation score: 0.728395\n",
      "Iteration 110, loss = 1.17249542\n",
      "Validation score: 0.728395\n",
      "Iteration 111, loss = 1.15951244\n",
      "Validation score: 0.728395\n",
      "Iteration 112, loss = 1.14679449\n",
      "Validation score: 0.728395\n",
      "Iteration 113, loss = 1.13420392\n",
      "Validation score: 0.728395\n",
      "Iteration 114, loss = 1.12177581\n",
      "Validation score: 0.728395\n",
      "Iteration 115, loss = 1.10963392\n",
      "Validation score: 0.740741\n",
      "Iteration 116, loss = 1.09755188\n",
      "Validation score: 0.740741\n",
      "Iteration 117, loss = 1.08565717\n",
      "Validation score: 0.740741\n",
      "Iteration 118, loss = 1.07394527\n",
      "Validation score: 0.740741\n",
      "Iteration 119, loss = 1.06235009\n",
      "Validation score: 0.740741\n",
      "Iteration 120, loss = 1.05095288\n",
      "Validation score: 0.740741\n",
      "Iteration 121, loss = 1.03973595\n",
      "Validation score: 0.753086\n",
      "Iteration 122, loss = 1.02854974\n",
      "Validation score: 0.753086\n",
      "Iteration 123, loss = 1.01760716\n",
      "Validation score: 0.753086\n",
      "Iteration 124, loss = 1.00684557\n",
      "Validation score: 0.753086\n",
      "Iteration 125, loss = 0.99613975\n",
      "Validation score: 0.753086\n",
      "Iteration 126, loss = 0.98562878\n",
      "Validation score: 0.753086\n",
      "Iteration 127, loss = 0.97524812\n",
      "Validation score: 0.753086\n",
      "Iteration 128, loss = 0.96504617\n",
      "Validation score: 0.753086\n",
      "Iteration 129, loss = 0.95492900\n",
      "Validation score: 0.753086\n",
      "Iteration 130, loss = 0.94495337\n",
      "Validation score: 0.753086\n",
      "Iteration 131, loss = 0.93511828\n",
      "Validation score: 0.777778\n",
      "Iteration 132, loss = 0.92544570\n",
      "Validation score: 0.777778\n",
      "Iteration 133, loss = 0.91586960\n",
      "Validation score: 0.777778\n",
      "Iteration 134, loss = 0.90646805\n",
      "Validation score: 0.790123\n",
      "Iteration 135, loss = 0.89710820\n",
      "Validation score: 0.790123\n",
      "Iteration 136, loss = 0.88795565\n",
      "Validation score: 0.790123\n",
      "Iteration 137, loss = 0.87891465\n",
      "Validation score: 0.790123\n",
      "Iteration 138, loss = 0.86995184\n",
      "Validation score: 0.790123\n",
      "Iteration 139, loss = 0.86109372\n",
      "Validation score: 0.790123\n",
      "Iteration 140, loss = 0.85244913\n",
      "Validation score: 0.790123\n",
      "Iteration 141, loss = 0.84383137\n",
      "Validation score: 0.790123\n",
      "Iteration 142, loss = 0.83538843\n",
      "Validation score: 0.790123\n",
      "Iteration 143, loss = 0.82707709\n",
      "Validation score: 0.790123\n",
      "Iteration 144, loss = 0.81875465\n",
      "Validation score: 0.790123\n",
      "Iteration 145, loss = 0.81062939\n",
      "Validation score: 0.790123\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Cross Validation Scores :  [0.67661692 0.67164179 0.07960199 0.80597015 0.73631841]\n",
      "Average Accuracy :  0.5940298507462687\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf_cross_val_result = cross_val_score(clf, X_train_pca, y_train, cv=5)\n",
    "\n",
    "print(\"Cross Validation Scores : \", clf_cross_val_result)\n",
    "print(\"Average Accuracy : \", np.mean(clf_cross_val_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# train nerual nertwork using Adaboosting\n",
    "adbost = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2), n_estimators=200, algorithm='SAMME.R',\n",
    "                            learning_rate=0.5, random_state=42)\n",
    "\n",
    "model = adbost.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.6262626262626263\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy : ', metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores :  [0.58       0.69666667 0.75333333 0.62       0.55      ]\n",
      "Average Accuracy :  0.64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "ada_cross_val_result = cross_val_score(adbost, X, y, cv=5)\n",
    "\n",
    "print(\"Cross Validation Scores : \", ada_cross_val_result)\n",
    "print(\"Average Accuracy : \", np.mean(ada_cross_val_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "14M376QiNVa2PMrATy9wvhC8nAZCKLG1j",
     "timestamp": 1675323166114
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
